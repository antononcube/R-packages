---
title: "Topics extraction from the play \"Hamplet\""
author: "Anton Antonov"
date: 2019-04-02
output: html_notebook
---

```{r}
library(LSAMon)
library(magrittr)
library(Matrix)
library(stopwords)
library(lattice)
library(OutlierIdentifiers)
```

```{r}
method <- "NNMF"
maxSteps <- 9
numberOfTopics <- 12
minNumberOfDocumentsPerTerm <- 5
```

# Introduction

# Topic extraction

```{r}
lsaObj <-
  LSAMonUnit( textHamlet   ) %>% 
  # LSAMonMakeDocumentTermMatrix( stemWordsQ = TRUE, stopWords = c( stopwords::stopwords(), "enter") ) %>% 
  LSAMonMakeDocumentTermMatrix( stemWordsQ = TRUE, stopWords = NULL, splitPattern = NULL ) %>% 
  LSAMonApplyTermWeightFunctions( "IDF", "None", "Cosine" ) %>% 
  LSAMonExtractTopics( numberOfTopics = numberOfTopics, minNumberOfDocumentsPerTerm = minNumberOfDocumentsPerTerm, maxSteps = maxSteps, method = "NNMF")
```


# The extracted topics

```{r}
lsaObj <-
  lsaObj %>% 
  LSAMonEchoTopicsTable(numberOfTerms = 20)
dfTopics <- lsaObj %>% LSAMonTakeValue
```

```{r}
dfTopics
```


```{r}
res <- dfTopics %>% dplyr::filter( TopicRank == 12 ) %>% dplyr::select( TermCoefficient )
OutlierPosition(res$TermCoefficient, SPLUSQuartileIdentifierParameters)
```

```{r}
dfTopics %>% dplyr::filter(TopicRank == 7 )
```


```{r}
sFactorsDF <- dfTopics %>% dplyr::select( TopicRank, TopicSignificanceFactor ) %>% unique()
lattice::xyplot( TopicSignificanceFactor ~ TopicRank, sFactorsDF )
```

```{r}
dfTopicsWideForm <- 
  reshape2::dcast( data = dfTopics, formula = TermRank ~ TopicName, value.var = "Term" )
dfTopicsWideForm
```

```{r}
lsaObj %>% LSAMonTakeTopicNames
```


```{r}
pairs <- expand.grid( names(dfTopicsWideForm), names(dfTopicsWideForm), stringsAsFactors = F)
res <- purrr::map2_dbl( pairs$Var1, pairs$Var2,
                        function(x,y) { 
                          if( x == y ) { 0 } else { length(intersect( dfTopicsWideForm[[x]], dfTopicsWideForm[[y]] ) ) } 
                        })
qMat <- matrix(res, nrow = ncol(dfTopicsWideForm) )
rownames(qMat) <- colnames(dfTopicsWideForm)
colnames(qMat) <- colnames(dfTopicsWideForm)
d3heatmap::d3heatmap(qMat, Rowv = F, Colv = F, scale = "none", colors = "Blues")
```

```{r}
summary(as.numeric(qMat))
```

## Statistical thesaurus extraction


```{r}
lsaObj <-
  lsaObj %>% 
  LSAMonExtractStatisticalThesaurus( searchWords = sort(c("king", "sword", "god", "ship", "joker", "poison", "queen")) )
nnsDF <- dplyr::bind_rows( lsaObj %>% LSAMonTakeValue )
nnsDF
```


```{r}
nnsDF2 <- 
  nnsDF %>% 
  dplyr::group_by( SearchTerm ) %>% 
  dplyr::arrange( Word.Distance ) %>% 
  dplyr::mutate( Rank = dplyr::row_number()) %>% 
  dplyr::select( SearchTerm, Rank, Word.Word )
reshape2::dcast( formula = SearchTerm ~ Rank, data = nnsDF2, value.var = "Word.Word" )
```

# Topics representation

```{r}
smat <- lsaObj %>% LSAMonTakeDocumentTermMatrix
```

Nearest Neighbors of "god" using the document-term matrix.

```{r}
dmat <- dist(t(smat))
ds <- as.matrix(dmat)["god",]
ds[order(ds)[1:12]]
```




### W matrix

```{r}
dim(lsaObj %>% LSAMonTakeW)
dim(lsaObj %>% LSAMonTakeH)
```

```{r, eval=F}
d3heatmap::d3heatmap( lsaObj %>% LSAMonTakeW, scale = "row", colors = "Blues" )
```

```{r, eval=F}
qMat <- (lsaObj %>% LSAMonTakeW) %*% t(lsaObj %>% LSAMonTakeW)
d3heatmap::d3heatmap( qMat, colors = "Blues" )
```

### Representation

```{r}
summary((lsaObj %>% LSAMonTakeW)@x)
```

```{r}
tags <- 1:nrow( lsaObj %>% LSAMonTakeW )
tags <- tags %/% 5
#tags <- setNames( tags, rownames(lsaObj %>% LSAMonTakeW) )
uniqueTags <- unique(tags)
tags
```

```{r}
lsaObj2 <- lsaObj %>% LSAMonRepresentDocumentTagsByTopics( tags = tags, minThreshold = 0.005 )
qMat <- as.matrix(lsaObj2 %>% LSAMonTakeValue)
qMat <- qMat[ uniqueTags, ]
d3heatmap::d3heatmap( qMat, Rowv = FALSE, Colv = TRUE, scale = "row", colors = "Blues" )
```


```{r}
dfTopicsWideForm
```

# Represent queries by terms

```{r}
names(lsaObj)
```


```{r}
qmat <- 
  lsaObj2 %>% 
  LSAMonRepresentByTerms( query = c("rotten castle in this country", "hamlet kills the king") ) %>% 
  LSAMonTakeValue
```

```{r}
qmat[ , colSums(qmat) > 0 ]
```

```{r}
textHamlet[1:8]
```

```{r}
qmat <- 
  lsaObj2 %>% 
  LSAMonRepresentByTerms( query = textHamlet[c(6,8)] ) %>% 
  LSAMonTakeValue
```

```{r}
as.matrix(qmat[ , colSums(qmat) > 0 ])
```

```{r}
qmat2 <- lsaObj2 %>% LSAMonTakeWeightedDocumentTermMatrix
qmat2 <- qmat2[c("id.6","id.8"),]
as.matrix(qmat2[ , colSums(qmat2) > 0 ])
```

# Represent queries by topics

```{r}
lsaObj2 <-
  LSAMonUnit( textHamlet   ) %>% 
  LSAMonMakeDocumentTermMatrix( stemWordsQ = FALSE, stopWords = NULL ) %>% 
  LSAMonApplyTermWeightFunctions( "IDF", "None", "Cosine" ) %>% 
  LSAMonExtractTopics( numberOfTopics = 10, minNumberOfDocumentsPerTerm = 10, method = "NNMF", maxSteps = 12 )
```


```{r}
focusInds <- c(6,8,10,12)
qmat <- 
  lsaObj2 %>% 
  LSAMonRepresentByTopics( query = textHamlet[focusInds] ) %>% 
  LSAMonTakeValue
qmat
```

```{r}
nnRes <- NonNegativeMatrixFactorization::NNMFNormalizeMatrixProduct( W = lsaObj2 %>% LSAMonTakeW, H = lsaObj2 %>% LSAMonTakeH, normalizeLeftQ = FALSE )
W <- nnRes$W
H <- nnRes$H
# colMaxes <- purrr::map_dbl( 1:ncol(W), function(i) sqrt( sum( W[,i] * W[,i]) ) )
# colMaxes <- purrr::map_dbl( 1:ncol(W), function(i) max(abs(W[,i])) )
# qmat <- qmat %*% Diagonal( x = 1/colMaxes )
qmat <- SparseMatrixRecommender::SMRApplyTermWeightFunctions( qmat, "None", "None", "Cosine")
cat("\n")  
as.matrix(qmat)
```

```{r}
qmat2 <- 
  lsaObj2 %>% 
  LSAMonRepresentByTopics( query = (lsaObj2 %>% LSAMonTakeDocumentTermMatrix)[c("id.6","id.8","id.10","id.12"),], applyTermWeightFunctionsQ = FALSE ) %>% 
  LSAMonTakeValue
qmat2 <- SparseMatrixRecommender::SMRApplyTermWeightFunctions( qmat2, "None", "None", "Cosine")
as.matrix(qmat2)
```

```{r}
qmat3 <- W[c("id.6","id.8","id.10","id.12"),]
qmat3 <- SparseMatrixRecommender::SMRApplyTermWeightFunctions( qmat3, "None", "None", "Cosine")
cat("\n")
as.matrix(qmat3)
```


